---
title: "Module 6 - Tuáº§n 2: Softmax Regression & MLFlow for Model Tracking"
date: 2025-11-21T10:00:00+07:00
description: "Tuáº§n 2 cá»§a Module 6 Ä‘i sÃ¢u vÃ o Softmax Regression cho bÃ i toÃ¡n phÃ¢n loáº¡i Ä‘a lá»›p, cÃ¹ng vá»›i á»©ng dá»¥ng thá»±c táº¿ trong MLOps báº±ng MLFlow. Sinh viÃªn Ä‘Æ°á»£c thá»±c hÃ nh tÃ­nh toÃ¡n, láº­p trÃ¬nh vá»›i Numpy vÃ  PyTorch, vÃ  tÃ¬m hiá»ƒu cÃ¡ch quáº£n lÃ½ mÃ´ hÃ¬nh báº±ng MLFlow."
image: images/Softmax_MLFlow.png
caption: Illustration by AI Vietnam Team
categories:
  - minutes
tags:
 
draft: false
---

ğŸ“ **All-in-One Course 2025 â€“ aivietnam.edu.vn**  
ğŸ“˜ **Study Guide: Module 6 â€“ Week 2**  
ğŸ§© **Chá»§ Ä‘á»:** Softmax Regression & MLFlow for Model Tracking and Versioning

> ğŸ’¡ *Tuáº§n nÃ y lÃ m quen vá»›i Softmax Regression â€“ má»™t mÃ´ hÃ¬nh then chá»‘t trong phÃ¢n loáº¡i Ä‘a lá»›p â€“ Ä‘á»“ng thá»i tÃ¬m hiá»ƒu vá» cÃ¡ch theo dÃµi vÃ  quáº£n lÃ½ mÃ´ hÃ¬nh Machine Learning qua MLFlow.*

---

## ğŸ“… **Lá»‹ch trÃ¬nh há»c vÃ  ná»™i dung chÃ­nh**

### ğŸ§‘â€ğŸ« **Thá»© 3 â€“ NgÃ y 11/11/2025**
_(Buá»•i warm-up â€“ TA ÄÄƒng NhÃ£)_

**Chá»§ Ä‘á»:** Softmax cÆ¡ báº£n  
**Ná»™i dung:**
- Tháº£o luáº­n cÃ¡c bÆ°á»›c trong **Softmax Regression**.  
- LÃ m vÃ­ dá»¥ tÃ­nh tay tá»«ng bÆ°á»›c Ä‘á»ƒ hiá»ƒu cÆ¡ cháº¿ tÃ­nh xÃ¡c suáº¥t vÃ  logit.  
- Chuáº©n bá»‹ cho pháº§n láº­p trÃ¬nh báº±ng Numpy trong buá»•i káº¿ tiáº¿p.

---

### ğŸ‘¨â€ğŸ« **Thá»© 4 â€“ NgÃ y 12/11/2025**
_(Buá»•i há»c chÃ­nh â€“ Dr. Quang Vinh)_

**Chá»§ Ä‘á»:** Softmax Regression cho PhÃ¢n loáº¡i Ä‘a lá»›p  
**Ná»™i dung:**
- Giá»›i thiá»‡u bÃ i toÃ¡n **multi-class classification**.  
- PhÃ¢n tÃ­ch cÃ´ng thá»©c **forward** vÃ  **backward propagation** trong Softmax.  
- CÃ i Ä‘áº·t hoÃ n chá»‰nh báº±ng **Numpy** Ä‘á»ƒ hiá»ƒu rÃµ cÆ¡ cháº¿ há»c vÃ  gradient.  

---

### âš™ï¸ **Thá»© 5 â€“ NgÃ y 13/11/2025**
_(Buá»•i MLOps â€“ TA Nguyá»…n Thuáº­n)_

**Chá»§ Ä‘á»:** MLFlow cho Model Tracking vÃ  Versioning  
**Ná»™i dung:**
- Giá»›i thiá»‡u tá»•ng quan vá» **MLFlow** trong há»‡ thá»‘ng MLOps.  
- CÃ¡ch theo dÃµi thÃ­ nghiá»‡m, log siÃªu tham sá»‘ vÃ  quáº£n lÃ½ phiÃªn báº£n mÃ´ hÃ¬nh.  
- Demo thá»±c hÃ nh nhá» vá» **Model Tracking & Versioning**.  

---

### ğŸ§  **Thá»© 6 â€“ NgÃ y 14/11/2025**
_(Buá»•i há»c chÃ­nh â€“ Dr. Quang Vinh)_

**Chá»§ Ä‘á»:** PyTorch Framework â€“ CÃ i Ä‘áº·t Regression vÃ  Classification  
**Ná»™i dung:**
- Giá»›i thiá»‡u cÆ¡ báº£n vá» **PyTorch Framework**.  
- CÃ i Ä‘áº·t cÃ¡c mÃ´ hÃ¬nh **Linear Regression**, **Logistic Regression** vÃ  **Softmax Regression** báº±ng PyTorch.  
- Tháº£o luáº­n vá» cÃ¡ch huáº¥n luyá»‡n, tÃ­nh loss vÃ  cáº­p nháº­t tham sá»‘ tá»± Ä‘á»™ng.  

---

### ğŸ”¬ **Thá»© 7 â€“ NgÃ y 15/11/2025**
_(Buá»•i nÃ¢ng cao â€“ Dr. ÄÃ¬nh Vinh)_

**Chá»§ Ä‘á»:** Loss Functions cho BÃ i toÃ¡n PhÃ¢n loáº¡i  
**Ná»™i dung:**
- Tháº£o luáº­n chi tiáº¿t cÃ¡c loáº¡i **Loss Function**: Cross-Entropy, Negative Log-Likelihood, Focal Loss, v.v.  
- So sÃ¡nh cÃ¡c hÃ m máº¥t mÃ¡t trong bá»‘i cáº£nh **class imbalance** vÃ  **multi-label**.  
- Tháº£o luáº­n hÆ°á»›ng nghiÃªn cá»©u má»Ÿ rá»™ng vÃ  nhá»¯ng thÃ¡ch thá»©c thá»±c táº¿.

---

### ğŸ‘¨â€ğŸ“ **Chá»§ nháº­t â€“ NgÃ y 16/11/2025**
_(Buá»•i Ã´n táº­p â€“ MSc. Quá»‘c ThÃ¡i)_

**Chá»§ Ä‘á»:** Softmax Regression â€“ Exercise  
**Ná»™i dung:**
- Ã”n táº­p nhanh ná»™i dung trá»ng tÃ¢m cá»§a buá»•i thá»© 4 vÃ  thá»© 6.  
- Giáº£i bÃ i táº­p tÃ­nh toÃ¡n gradient, loss, vÃ  dá»± Ä‘oÃ¡n xÃ¡c suáº¥t.  
- Cá»§ng cá»‘ ká»¹ nÄƒng láº­p trÃ¬nh Softmax Regression.  

---

## ğŸ“Œ **Äiá»ƒm nháº¥n vÃ  kiáº¿n thá»©c chÃ­nh**

### âœ… **Softmax Regression â€“ PhÃ¢n loáº¡i Ä‘a lá»›p**
- Biá»ƒu diá»…n xÃ¡c suáº¥t cho tá»«ng lá»›p:
  $$
  P(y_i = k \mid \mathbf{x}_i) = \frac{e^{\mathbf{w}_k^\top \mathbf{x}_i}}{\sum_j e^{\mathbf{w}_j^\top \mathbf{x}_i}}
  $$
- MÃ´ hÃ¬nh tá»•ng quÃ¡t cho **multi-class classification**.  
- Káº¿t ná»‘i trá»±c tiáº¿p vá»›i **Logistic Regression** vÃ  **Cross-Entropy Loss**.  
- PhÃ¢n tÃ­ch **gradient descent** trong khÃ´ng gian nhiá»u chiá»u.

---

### âœ… **PyTorch â€“ Triá»ƒn khai hiá»‡n Ä‘áº¡i**
- Sá»­ dá»¥ng `torch.nn.Module` Ä‘á»ƒ táº¡o mÃ´ hÃ¬nh Regression.  
- Sá»­ dá»¥ng `torch.optim` cho cáº­p nháº­t tham sá»‘ tá»± Ä‘á»™ng.  
- Hiá»ƒu cÆ¡ cháº¿ **autograd** trong viá»‡c lan truyá»n gradient.

---

### âœ… **MLOps vá»›i MLFlow**
- Theo dÃµi vÃ  ghi láº¡i toÃ n bá»™ quÃ¡ trÃ¬nh huáº¥n luyá»‡n (metrics, parameters, model files).  
- So sÃ¡nh cÃ¡c phiÃªn báº£n mÃ´ hÃ¬nh qua UI hoáº·c CLI.  
- LÆ°u trá»¯ mÃ´ hÃ¬nh vÃ  phá»¥c há»“i Ä‘á»ƒ **deploy hoáº·c fine-tune**.

---

### âœ… **Loss Functions nÃ¢ng cao**
- PhÃ¢n biá»‡t cÃ¡c loáº¡i loss trong phÃ¢n loáº¡i:
  - `CrossEntropyLoss`
  - `KLDivLoss`
  - `Focal Loss`
- á»¨ng dá»¥ng tá»«ng loáº¡i loss cho bÃ i toÃ¡n cÃ³ dá»¯ liá»‡u máº¥t cÃ¢n báº±ng.

---

## ğŸ“š **TÃ i liá»‡u Ä‘i kÃ¨m**

{{< pdf src="/Time-Series-Team-Hub/pdf/M6W2D2+3_Softmax.pdf" title="M6W2D_Softmax" height="700px" >}}

{{< pdf src="/Time-Series-Team-Hub/pdf/M6W2D4+6_Prometheus_Grafana.pdf" title="M6W2D4+6_Prometheus_Grafana_MLOPs" height="700px" >}}


{{< pdf src="/Time-Series-Team-Hub/pdf/M6W2D7_LossFuncForClassify.pdf" title="M6W2D7_LossFuncForClassify" height="700px" >}}


---

ğŸ§  _Repository managed by [AI Vietnam Team Hub](https://github.com/AI-Vietnam-Institution/All-in-One-Course)_  
ğŸ“ _Blog thuá»™c series **All-in-One Course 2025** â€“ chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o toÃ n diá»‡n AI, Data Science, vÃ  MLOps táº¡i [aivietnam.edu.vn](https://aivietnam.edu.vn)_
