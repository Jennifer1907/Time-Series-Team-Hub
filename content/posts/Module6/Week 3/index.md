---
title: "Module 6 - Tuáº§n 3: Multilayer Perceptron & Metrics for Classification"
date: 2025-11-28T10:00:00+07:00
description: "Tuáº§n 3 cá»§a Module 6 nÃ¢ng cáº¥p tá»« Softmax Regression lÃªn Multilayer Perceptron (MLP), Ä‘i kÃ¨m kháº£o sÃ¡t Activation, Initialization, Optimizer vÃ  cÃ¡c há»‡ metric dÃ nh cho bÃ i toÃ¡n phÃ¢n loáº¡i. Sinh viÃªn vá»«a há»c cÃ´ng thá»©c forward/backward, vá»«a code PyTorch, Ä‘á»“ng thá»i káº¿t ná»‘i vá»›i tháº¿ giá»›i MLOps qua Prometheus & Grafana."
image: images/MLP_Metrics.png
caption: Illustration by AI Vietnam Team
categories:
  - minutes
tags:

draft: false
---

ğŸ“ **All-in-One Course 2025 â€“ aivietnam.edu.vn**  
ğŸ“˜ **Study Guide: Module 6 â€“ Week 3**  
ğŸ§© **Chá»§ Ä‘á»:** Multilayer Perceptron & Metrics for Classification  

> ğŸ’¡ *Tuáº§n nÃ y lÃ  bÆ°á»›c chuyá»ƒn tá»« â€œmÃ´ hÃ¬nh tuyáº¿n tÃ­nhâ€ sang â€œmáº¡ng nÆ¡-ron sÃ¢uâ€: MLP, Activation, Initialization, Optimizer â€“ vÃ  cÃ¡ch Ä‘o lÆ°á»ng mÃ´ hÃ¬nh phÃ¢n loáº¡i báº±ng cÃ¡c há»‡ metric khÃ¡c nhau Ä‘á»ƒ chuáº©n bá»‹ cho bÃ i Loss á»Ÿ cÃ¡c tuáº§n sau.*

---

## ğŸ“… **Lá»‹ch trÃ¬nh há»c vÃ  ná»™i dung chÃ­nh**

### ğŸ§‘â€ğŸ« **Thá»© 3 â€“ NgÃ y 18/11/2025**  
*(Buá»•i warm-up â€“ MSc. Quá»‘c ThÃ¡i)*  

**Chá»§ Ä‘á»:** MLP cÆ¡ báº£n â€“ tá»« Perceptron tá»›i Multi-layer Perceptron  
**Ná»™i dung:**

* Nháº¯c láº¡i Softmax/Logistic Regression, lÃ½ do pháº£i **thÃªm hidden layer**.
* Tháº£o luáº­n cÃ¡c bÆ°á»›c trong **MLP pipeline**: chuáº©n bá»‹ dá»¯ liá»‡u â†’ chuáº©n hÃ³a â†’ xÃ¢y network â†’ khá»Ÿi táº¡o tham sá»‘.
* LÃ m vÃ­ dá»¥ tÃ­nh tay forward qua 1 hidden layer:
  
  $$
  \mathbf{h} = \sigma(W_1 \mathbf{x} + \mathbf{b}_1), \quad
  \hat{\mathbf{y}} = \text{softmax}(W_2 \mathbf{h} + \mathbf{b}_2)
  $$

---

### ğŸ‘¨â€ğŸ« **Thá»© 4 â€“ NgÃ y 19/11/2025**  
*(Buá»•i há»c chÃ­nh â€“ Dr. Quang Vinh)*  

**Chá»§ Ä‘á»:** XÃ¢y dá»±ng MLP â€“ Forward & Backward  
**Ná»™i dung:**

* So sÃ¡nh **Softmax Regression vs MLP**.
* Giáº£i thÃ­ch forward/backward nhiá»u layer báº±ng chain rule.
* CÃ¡c cÃ¢u há»i khi design network:

  * Bao nhiÃªu **hidden layers**, má»—i layer bao nhiÃªu **neurons**?
  * Äáº·t activation á»Ÿ Ä‘Ã¢u vÃ  vÃ¬ sao â€œaffine â†’ non-linear â†’ affineâ€ má»›i tÄƒng Ä‘Æ°á»£c nÄƒng lá»±c biá»ƒu diá»…n.
  * Khi nÃ o dÃ¹ng `nn.ReLU()` trong `__init__` vs `F.relu()` trong `forward`.

* CÃ i Ä‘áº·t MLP báº±ng **PyTorch** vÃ  xem kÃ­ch thÆ°á»›c tá»«ng layer.

---

### âš™ï¸ **Thá»© 5 â€“ NgÃ y 20/11/2025**  
*(Buá»•i MLOps â€“ TA Nguyá»…n Thuáº­n)*  

**Chá»§ Ä‘á»:** Prometheus & Grafana â€“ Monitoring há»‡ thá»‘ng AI  
**Ná»™i dung:**

* Káº¿t ná»‘i MLFlow tuáº§n trÆ°á»›c sang monitoring.
* Pipeline: MLP â†’ log metrics â†’ Prometheus â†’ Grafana dashboard.
* Demo tracking loss, accuracy, batch time, GPU memory.

---

### ğŸ§  **Thá»© 6 â€“ NgÃ y 21/11/2025**  
*(Buá»•i há»c chÃ­nh â€“ Dr. Quang Vinh)*  

**Chá»§ Ä‘á»:** Activation, Initialization & Optimizer  

**Ná»™i dung:**

* CÃ¡c activation quan trá»ng:
  - ReLU, LeakyReLU, GELU, Sigmoid, Tanh.
* VÃ¬ sao activation náº±m giá»¯a cÃ¡c fully-connected layers.
* Initialization:
  - He init cho ReLU  
  - Xavier cho Tanh/Sigmoid
* Optimizer:
  - SGD + Momentum vs Adam

---

### ğŸ“Š **Thá»© 7 â€“ NgÃ y 22/11/2025**  
*(Buá»•i chuyÃªn Ä‘á» â€“ Dr. ÄÃ¬nh Vinh)*

**Chá»§ Ä‘á»:** Metrics cho phÃ¢n loáº¡i  

**Ná»™i dung:**

* Confusion Matrix: TP, TN, FP, FN.
* Binary:
  - Accuracy, Precision, Recall, Specificity, FPR, FNR, F1.
* Multiclass:
  - Micro/Macro/Weighted F1, Balanced Accuracy, \(F_\beta\).
* Multilabel:
  - Exact Match, 0/1 Loss, Hamming Loss.
* VÃ¬ sao metric khÃ´ng differentiable â†’ dÃ¹ng Loss lÃ m surrogate.

---

### ğŸ‘¨â€ğŸ“ **Chá»§ nháº­t â€“ NgÃ y 23/11/2025**  
*(Buá»•i Ã´n táº­p â€“ TA ÄÃ¬nh Tháº¯ng)*  

**Chá»§ Ä‘á»:** MLP â€“ Exercise & Mini Project  
**Ná»™i dung:**

* TÃ³m táº¯t forward/backward, activation, init, optimizer.
* BÃ i táº­p giáº¥y + code (ReLU â†’ GELU).
* Cháº¡y MLP, log Accuracy/F1/Recall/Balanced Accuracy.

---

## ğŸ“Œ **Äiá»ƒm nháº¥n vÃ  kiáº¿n thá»©c chÃ­nh**

### âœ… Tá»« Softmax Regression tá»›i MLP

* Softmax Regression lÃ  mÃ´ hÃ¬nh tuyáº¿n tÃ­nh:  
  $\hat{\mathbf{y}} = \text{softmax}(W\mathbf{x} + \mathbf{b})$

* MLP thÃªm hidden layers + activation:  
  $\mathbf{h}^{(l)} = \sigma(W^{(l)} \mathbf{h}^{(l-1)} + \mathbf{b}^{(l)})$

---

### âœ… Activation â€“ Initialization â€“ Optimizer

* ReLU: nhanh nhÆ°ng cÃ³ dying ReLU.  
* LeakyReLU/GELU: giá»¯ gradient tá»‘t hÆ¡n.  
* Initialization:
  - He init â†” ReLU  
  - Xavier â†” Sigmoid/Tanh  
* Optimizer:
  - SGD (á»•n nhÆ°ng cáº§n tuning)  
  - Adam (adaptive learning rate)

---

### âœ… Backprop qua nhiá»u layer

Backprop chá»‰ lÃ  chain rule láº·p láº¡i:

$$
\frac{\partial \mathcal{L}}{\partial W^{(L)}} =
\frac{\partial \mathcal{L}}{\partial \hat{\mathbf{y}}}
\frac{\partial \hat{\mathbf{y}}}{\partial W^{(L)}}
$$

Gradient lan tá»« output vá» input â†’ dá»… gÃ¢y vanishing/exploding.

---

### âœ… Metrics & Loss

* **Binary:** Accuracy, Precision, Recall, Specificity, F1.  
* **Multiclass:** Micro/Macro/Weighted F1, Balanced Accuracy.  
* **Multilabel:** Exact Match, Hamming Loss.  

Metric = Ä‘o cháº¥t lÆ°á»£ng.  
Loss = Ä‘á»ƒ tá»‘i Æ°u báº±ng gradient descent.

Metric khÃ´ng differentiable â†’ dÃ¹ng Loss surrogate nhÆ° Cross-Entropy.

---

## ğŸ“š **TÃ i liá»‡u Ä‘i kÃ¨m**

* {{< pdf src="/Time-Series-Team-Hub/pdf/M06W03-StudyGuide.pdf" title="M06W03 â€“ Study Guide" height="700px" >}}
* {{< pdf src="/Time-Series-Team-Hub/pdf/M06W03-MLP.pdf" title="M06W03 â€“ Multilayer Perceptron Slides" height="700px" >}}
* {{< pdf src="/Time-Series-Team-Hub/pdf/M6W2D4+6_Prometheus_Grafana.pdf" title="M6W2D4+6_Prometheus_Grafana_MLOPs" height="700px" >}}
* {{< pdf src="/Time-Series-Team-Hub/pdf/M06W03-InsightIntoMLP.pdf" title="M06W03 â€“ Insight into MLP" height="700px" >}}
* {{< pdf src="/Time-Series-Team-Hub/pdf/M06W03-MetricsForClassification.pdf" title="M06W03 â€“ Metrics for Classification" height="700px" >}}

---
ğŸ§  *Repository managed by [AI Vietnam Team Hub](https://github.com/AI-Vietnam-Institution/All-in-One-Course)*
ğŸ“ *Blog thuá»™c series **All-in-One Course 2025** â€“ chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o toÃ n diá»‡n AI, Data Science, vÃ  MLOps táº¡i [aivietnam.edu.vn](https://aivietnam.edu.vn)*
ğŸ§  *Repository managed by AI Vietnam Team Hub*  
ğŸ“ *Blog thuá»™c series All-in-One Course 2025*
